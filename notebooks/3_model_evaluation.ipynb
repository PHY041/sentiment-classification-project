{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoyangpang/Desktop/Y3S1/SC4002 Natural Language Processing/assignment/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/haoyangpang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "\n",
    "from data_loader import load_data\n",
    "from embeddings import load_pretrained_embeddings\n",
    "from models import RNNModel, BiLSTMModel, BiGRUModel, CNNModel\n",
    "from utils import train_model, evaluate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('mps' if torch.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/haoyangpang/Desktop/Y3S1/SC4002 Natural Language Processing/assignment/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())  \n",
    "os.chdir('/Users/haoyangpang/Desktop/Y3S1/SC4002 Natural Language Processing/assignment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/haoyangpang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Load the saved vocabulary\n",
    "with open('vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "batch_size = 32\n",
    "max_len = 100\n",
    "\n",
    "train_loader, val_loader, test_loader, _ = load_data(batch_size, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "embedding_file = 'glove.6B.300d.txt'\n",
    "\n",
    "# Load embedding matrix\n",
    "embedding_matrix = load_pretrained_embeddings(vocab, embedding_dim, embedding_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancement 1: Updating Word Embeddings, modified RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNModel(\n",
       "  (embedding): Embedding(15813, 300)\n",
       "  (rnn): RNN(300, 256, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "output_size = 2  # Positive or Negative sentiment\n",
    "\n",
    "# Initialize the RNN model with trainable embeddings\n",
    "model_update_emb = RNNModel(embedding_matrix, hidden_size, output_size, freeze=False)\n",
    "model_update_emb.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 267/267 [00:20<00:00, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7135, Val Acc: 0.4737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 267/267 [00:18<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.6994, Val Acc: 0.4728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 267/267 [00:18<00:00, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.6997, Val Acc: 0.4709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 267/267 [00:18<00:00, 14.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.7051, Val Acc: 0.4700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 267/267 [00:18<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.7014, Val Acc: 0.5291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 267/267 [00:18<00:00, 14.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.6988, Val Acc: 0.5291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 267/267 [00:18<00:00, 14.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.7047, Val Acc: 0.4700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 267/267 [00:18<00:00, 14.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.6989, Val Acc: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 267/267 [00:18<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.6990, Val Acc: 0.4709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 267/267 [00:18<00:00, 14.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.6964, Val Acc: 0.5291\n",
      "Best Validation Accuracy: 0.5291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/t6kz6qx12y73h21vglf5plvm0000gn/T/ipykernel_10671/1505103534.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_update_emb.load_state_dict(torch.load('best_model.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with Updated Embeddings: 0.5141\n"
     ]
    }
   ],
   "source": [
    "# Define loss and optimizer\n",
    "num_epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_update_emb.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_losses, val_accuracies = train_model(\n",
    "    model_update_emb, train_loader, val_loader, criterion, optimizer, num_epochs, device\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "model_update_emb.load_state_dict(torch.load('best_model.pt'))\n",
    "test_accuracy_update_emb = evaluate_model(model_update_emb, test_loader, device)\n",
    "print(f\"Test Accuracy with Updated Embeddings: {test_accuracy_update_emb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3(a): Report the accuracy score when updating word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: The test accuracy when the word embeddings are updated during training is 0.5141"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3(b): Report the accuracy score when applying OOV handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancement 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Since we have already initialized OOV embeddings and allowed them to be updated, the model from Enhancement 1 includes this change. So the Test Accuracty is also 0.5141"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancement 3: Using BiLSTM and BiGRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMModel(\n",
       "  (embedding): Embedding(15813, 300)\n",
       "  (lstm): LSTM(300, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "output_size = 2\n",
    "\n",
    "model_bilstm = BiLSTMModel(embedding_matrix, hidden_size, output_size)\n",
    "model_bilstm.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 267/267 [00:04<00:00, 56.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6650, Val Acc: 0.6285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 267/267 [00:03<00:00, 77.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.5987, Val Acc: 0.6567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 267/267 [00:03<00:00, 77.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.5442, Val Acc: 0.6745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 267/267 [00:03<00:00, 77.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.4648, Val Acc: 0.6735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 267/267 [00:03<00:00, 77.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.3720, Val Acc: 0.6876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 267/267 [00:03<00:00, 77.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.2530, Val Acc: 0.6773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 267/267 [00:03<00:00, 76.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.1482, Val Acc: 0.6707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 267/267 [00:03<00:00, 77.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.0851, Val Acc: 0.6651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 267/267 [00:03<00:00, 76.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.0424, Val Acc: 0.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 267/267 [00:03<00:00, 77.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0293, Val Acc: 0.6670\n",
      "Best Validation Accuracy: 0.6876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/t6kz6qx12y73h21vglf5plvm0000gn/T/ipykernel_10671/3697843252.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_bilstm.load_state_dict(torch.load('best_model.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with BiLSTM: 0.6717\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_bilstm.parameters(), lr=0.001)\n",
    "\n",
    "train_losses, val_accuracies = train_model(\n",
    "    model_bilstm, train_loader, val_loader, criterion, optimizer, num_epochs, device\n",
    ")\n",
    "\n",
    "model_bilstm.load_state_dict(torch.load('best_model.pt'))\n",
    "test_accuracy_bilstm = evaluate_model(model_bilstm, test_loader, device)\n",
    "print(f\"Test Accuracy with BiLSTM: {test_accuracy_bilstm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiGRUModel(\n",
       "  (embedding): Embedding(15813, 300)\n",
       "  (gru): GRU(300, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bigru = BiGRUModel(embedding_matrix, hidden_size, output_size)\n",
    "model_bigru.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 267/267 [00:39<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6566, Val Acc: 0.6276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 267/267 [00:39<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.5877, Val Acc: 0.6773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 267/267 [00:39<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.5233, Val Acc: 0.6811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 267/267 [00:39<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.4419, Val Acc: 0.7017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 267/267 [00:39<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.3311, Val Acc: 0.7054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 267/267 [03:20<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.2029, Val Acc: 0.7083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 267/267 [18:40<00:00,  4.20s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.1127, Val Acc: 0.6923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 267/267 [02:21<00:00,  1.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.0541, Val Acc: 0.6942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 267/267 [00:38<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.0290, Val Acc: 0.6867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 267/267 [00:39<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0326, Val Acc: 0.6867\n",
      "Best Validation Accuracy: 0.7083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/t6kz6qx12y73h21vglf5plvm0000gn/T/ipykernel_10671/138486322.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_bigru.load_state_dict(torch.load('best_model.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with BiGRU: 0.6811\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_bigru.parameters(), lr=0.001)\n",
    "\n",
    "train_losses, val_accuracies = train_model(\n",
    "    model_bigru, train_loader, val_loader, criterion, optimizer, num_epochs, device\n",
    ")\n",
    "\n",
    "model_bigru.load_state_dict(torch.load('best_model.pt'))\n",
    "test_accuracy_bigru = evaluate_model(model_bigru, test_loader, device)\n",
    "print(f\"Test Accuracy with BiGRU: {test_accuracy_bigru:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3(c): Report the accuracy scores of BiLSTM and BiGRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Test Accuracy with BiLSTM: 0.6717\n",
    "Test Accuracy with BiGRU: 0.6811"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhancement 4: Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (embedding): Embedding(15813, 300)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=300, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn = CNNModel(embedding_matrix, output_size)\n",
    "model_cnn.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 267/267 [00:05<00:00, 49.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6590, Val Acc: 0.6323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 267/267 [00:04<00:00, 65.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.5581, Val Acc: 0.6632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 267/267 [00:04<00:00, 64.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.4462, Val Acc: 0.6726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 267/267 [00:04<00:00, 65.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.3477, Val Acc: 0.6773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 267/267 [00:04<00:00, 64.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.2581, Val Acc: 0.6632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 267/267 [00:04<00:00, 65.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.2021, Val Acc: 0.6632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 267/267 [00:04<00:00, 65.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.1599, Val Acc: 0.6670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 267/267 [00:04<00:00, 65.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.1376, Val Acc: 0.6670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 267/267 [00:04<00:00, 65.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.1229, Val Acc: 0.6707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 267/267 [00:04<00:00, 65.60it/s]\n",
      "/var/folders/s4/t6kz6qx12y73h21vglf5plvm0000gn/T/ipykernel_10671/1803200180.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_cnn.load_state_dict(torch.load('best_model.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.1005, Val Acc: 0.6764\n",
      "Best Validation Accuracy: 0.6773\n",
      "Test Accuracy with CNN: 0.6745\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
    "\n",
    "train_losses, val_accuracies = train_model(\n",
    "    model_cnn, train_loader, val_loader, criterion, optimizer, num_epochs, device\n",
    ")\n",
    "\n",
    "model_cnn.load_state_dict(torch.load('best_model.pt'))\n",
    "test_accuracy_cnn = evaluate_model(model_cnn, test_loader, device)\n",
    "print(f\"Test Accuracy with CNN: {test_accuracy_cnn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3(d): Report the accuracy scores of CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy with CNN is 0.6745"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhancement 5: Further Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 267/267 [00:04<00:00, 56.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6212, Val Acc: 0.6951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 267/267 [00:03<00:00, 78.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.3564, Val Acc: 0.7505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 267/267 [00:03<00:00, 78.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 0.1659, Val Acc: 0.7430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 267/267 [00:03<00:00, 77.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.0650, Val Acc: 0.7270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 267/267 [00:03<00:00, 77.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 0.0283, Val Acc: 0.7298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 267/267 [00:03<00:00, 77.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.0074, Val Acc: 0.7233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 267/267 [00:03<00:00, 77.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.0025, Val Acc: 0.7195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 267/267 [00:03<00:00, 76.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.0011, Val Acc: 0.7261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 267/267 [00:03<00:00, 76.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.0007, Val Acc: 0.7251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 267/267 [00:03<00:00, 76.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.0005, Val Acc: 0.7233\n",
      "Best Validation Accuracy: 0.7505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/t6kz6qx12y73h21vglf5plvm0000gn/T/ipykernel_10671/2231005473.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_bilstm_attn.load_state_dict(torch.load('best_model.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with BiLSTM + Attention: 0.7749\n"
     ]
    }
   ],
   "source": [
    "# In your notebook or training script\n",
    "from models.bilstm_attention import BiLSTMAttentionModel\n",
    "\n",
    "hidden_size = 128\n",
    "output_size = 2\n",
    "\n",
    "model_bilstm_attn = BiLSTMAttentionModel(\n",
    "    embedding_matrix, hidden_size, output_size, freeze_embeddings=False\n",
    ")\n",
    "model_bilstm_attn.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_bilstm_attn.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "train_losses, val_accuracies = train_model(\n",
    "    model_bilstm_attn, train_loader, val_loader, criterion, optimizer, num_epochs, device\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "model_bilstm_attn.load_state_dict(torch.load('best_model.pt'))\n",
    "test_accuracy_bilstm_attn = evaluate_model(model_bilstm_attn, test_loader, device)\n",
    "print(f\"Test Accuracy with BiLSTM + Attention: {test_accuracy_bilstm_attn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3(e): Describe Your Final Improvement Strategy and Report Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Answer:\n",
    "\n",
    "Improvement Strategy:\n",
    "\n",
    "We implemented an attention mechanism on top of the BiLSTM model to allow the model to focus on the most informative words in the sentence. The attention mechanism computes a weighted sum of the LSTM outputs, where the weights are learned to emphasize important features. This lead to the increase in accuracy from 0.6717 to 0.7749.\n",
    "\n",
    "The attention mechanism helps the model to capture long-range dependencies and focus on key parts of the input that are most relevant for the classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3(f): Compare Results and Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of Test Accuracies:\n",
    "\n",
    "Model\tTest Accuracy\n",
    "RNN (static embeddings)\t0.5000\n",
    "RNN (updated embeddings)\t0.5141\n",
    "BiGRU\t0.6811\n",
    "BiLSTM\t0.6717\n",
    "CNN\t0.6745\n",
    "BiLSTM + Attention\t0.7749\n",
    "Observations:\n",
    "\n",
    "Minimal Improvement from Updating Embeddings:\n",
    "\n",
    "The RNN model with static embeddings achieved a test accuracy of 50.00%, which is equivalent to random guessing in a binary classification task.\n",
    "Updating the word embeddings during training led to a slight improvement, increasing the test accuracy to 51.41%.\n",
    "Interpretation: The minimal improvement suggests that the simple RNN architecture struggles to capture the complexity of the sentiment classification task, even when the embeddings are fine-tuned.\n",
    "\n",
    "Significant Performance Boost with Advanced Architectures:\n",
    "\n",
    "BiGRU, BiLSTM, and CNN models show substantial improvements over the simple RNN:\n",
    "BiGRU: 68.11% test accuracy.\n",
    "BiLSTM: 67.17% test accuracy.\n",
    "CNN: 67.45% test accuracy.\n",
    "Interpretation: These architectures are better at capturing sequential dependencies and extracting relevant features from the text, leading to higher accuracy.\n",
    "\n",
    "Best Performance with BiLSTM + Attention:\n",
    "\n",
    "The BiLSTM model enhanced with an attention mechanism achieved the highest test accuracy of 77.49%.\n",
    "Interpretation: The attention mechanism allows the model to focus on the most informative words in each sentence, effectively capturing the nuances necessary for sentiment classification.\n",
    "\n",
    "Comparison Between BiGRU and BiLSTM:\n",
    "\n",
    "The BiGRU slightly outperformed the BiLSTM model:\n",
    "BiGRU: 68.11%\n",
    "BiLSTM: 67.17%\n",
    "Interpretation: While both models are effective, the GRU's simpler architecture may prevent overfitting and result in better generalization in this case.\n",
    "\n",
    "CNN Model Performance:\n",
    "\n",
    "The CNN model achieved a test accuracy of 67.45%, comparable to the BiLSTM and BiGRU models.\n",
    "Interpretation: CNNs are effective at capturing local patterns and n-gram features, which are valuable for sentiment analysis.\n",
    "\n",
    "Conclusions:\n",
    "\n",
    "Effectiveness of Advanced Models:\n",
    "\n",
    "Transitioning from a simple RNN to more sophisticated architectures like BiGRU, BiLSTM, and CNN significantly enhances model performance.\n",
    "These models are better suited for capturing complex patterns in textual data.\n",
    "\n",
    "Impact of Attention Mechanism:\n",
    "\n",
    "Incorporating an attention mechanism into the BiLSTM model leads to a substantial performance boost, achieving the highest accuracy.\n",
    "Reason: Attention allows the model to weigh the importance of different words, focusing on those most relevant to the sentiment classification task.\n",
    "\n",
    "Limited Benefit from Updating Embeddings Alone:\n",
    "\n",
    "Simply updating the embeddings in the RNN model does not lead to a meaningful improvement.\n",
    "Implication: The model's capacity plays a crucial role, and without a suitable architecture, fine-tuning embeddings is insufficient.\n",
    "Recommendation for Future Work:\n",
    "\n",
    "Model Complexity: Employ models with greater capacity and ability to capture sequential dependencies and contextual information.\n",
    "Attention Mechanisms: Explore attention mechanisms further, as they have demonstrated significant benefits.\n",
    "Hyperparameter Tuning: Experiment with different hyperparameters (e.g., learning rate, batch size, hidden units) to optimize performance.\n",
    "Data Augmentation: Consider augmenting the dataset to provide the model with more varied training examples.\n",
    "\n",
    "Overall Assessment:\n",
    "\n",
    "The results clearly demonstrate that the choice of model architecture has a profound impact on performance in sentiment classification tasks.\n",
    "Incorporating advanced models and techniques like bidirectional layers and attention mechanisms is essential for capturing the complexities of natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
